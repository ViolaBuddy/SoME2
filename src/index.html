<!DOCTYPE html>
<html>
<head>
	<title>Clock Solitaire</title>
	<link rel="stylesheet" type="text/css" href="indexstyle.css">
    <script type="text/javascript" src="PlayingCards.js"></script>
    <script type="text/javascript" id="MathJax-script" async
    	src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
	</script>
</head>
<body>
<h1>Clock Solitaire</h1>
<div class="content">
	<h2>The Game</h2>
	<p>This is Clock Solitaire, a solitaire game played with a standard 52-card deck.</p>
	<details>
		<summary>Rules (click to reveal)</summary>
		<div>
			<p><strong>Setup:</strong> Arrange your cards in twelve piles of four in a circle, like the twelve numbers on a clock face. Put the final pile of four in the center; this represents the clock striking 13.</p>
			<p><strong>Gameplay:</strong> A move in this game consists of taking a card from a pile on the clock and putting it face-up in the waste pile. Your first move is from the central 13 o'clock pile.</p>
			<p>After that, each subsequent move is from the pile indicated by the value of the card that you just placed in the waste pile in the previous move. For example, if the first card is a Two, your next move would be from the pile in the 2 o'clock position. Aces are 1 o'clock, Jacks are 11 o'clock, Queens are 12 o'clock, and Kings are the 13 o'clock pile in the center.</p>
			<p>In this digital version, to make a move, click on a facedown card in the right pile to move it to the waste. (Clicking on a card in any wrong pile will do nothing.)</p>
			<p><strong>Victory and loss conditions:</strong> Your goal is to move all the cards into the waste pile&mdash;but if a card points you to a pile that's already empty, that's game over!</p>
		</div>
	</details>
	<iframe src="basicgame.html" title="Clock Solitaire" id="basicgame" class="gameiframe"></iframe>
	<p>If you're just here for the game and not the math that describes the game&hellip; well, that's it; there's not much more here for you. A not-very-exciting game with no strategy on the part of the player. If anything, it's a quiz on how well you remember the positions on a clock&mdash;something that many of us are out of practice with due to the prevalence of digital clocks today.</p>
	<p>It's actually a bit more engaging if you ever get a chance to play it with a physical deck of cards. There's still no strategy or choice, of course, but there's something calming and almost meditative about methodically moving cards one by one without needing to think about strategy.</p>
	<p>But if you're ready to dive into just a little bit of the math, carry on!</p>
</div>

<div class="content">
	<h2>Great, so what math-y things are we talking about?</h2>
	<p>Well, the most obvious question to ask is "What's the chance of winning the game?" So let's look at that.</p>
	<p>Before we start asking questions about the game, it'd be good to just play through several complete games just to see the game a few different times. But you're probably getting tired of hunting and clicking. Fortunately, as I said, this game involves absolutely no choice whatsoever, which means it's easy to automate! So if you're tired of clicking, try this one:</p>
	<iframe src="autogame.html" title="Clock Solitaire (Auto)" id="autogame" class="gameiframe"></iframe> 
	<p>After running through a couple games, there's actually something else that becomes pretty apparent, even though it doesn't seem to have any connection to the question about our win rate: when the game ends, no matter if that's because we won or lost, the last card on our waste pile is always a King. That's interesting&hellip; but not what we're here to investigate! Let's stay focused! Keep that observation in the back of your mind, though; we'll come back to it later.</p>
	<p>But back on track, something you might have noticed that's actually <em>relevant</em> is that the game is generally not very likely to be won. Depending on your luck, maybe you haven't even seen a winning game at all. But let's try to quantify this.</p>
</div>

<div class="content">
	<h2>Onward to Victory (with Some Small Probability)</h2>
	<p>One way to find out the probability of something is to just do it over and over again. And, well, we set up this whole automatic simulator; we might as well use it to find out the victory rate experimentally. Here's the same simulator, but it lets you run multiple runs of the game with the click of one button.</p>
	<iframe src="victorypercentagegame.html" title="Clock Solitaire, with percentage" id="victorypercentagegame" class="gameiframe"></iframe>
	<p>Okay, great, we have an experimental number. But, uh&hellip; so now what? This is a simulation, so I have no idea what number you have. When I clicked the 100&times; button I got 7/100, so 7%, but maybe you got 5%, maybe you got 8%, I don't know. And, well, of course; that's the nature of randomness. But everyone's playing the same game: there should be one rate underlying it all, a true victory rate that's a property of the game itself that doesn't change from experiment to experiment. Can we peel back the randomness and somehow get this "true" value?</p>
	<p>One instinct we might have is to just simulate it a whole lot of times. The more times we do it, the closer our experimental value should trend towards the true value. So we can just keep pressing those autoplay buttons more and more until we reach&hellip;</p>
	<p>Actually, until we reach what? We're never going to reach <em>exactly</em> the true rate. Or, well, technically we might land on it by chance after a random amount of trials, for example, the 31415th simulation. But even if we did, we wouldn't <em>know</em> that we did, which is basically the same thing as having not gotten it right at all. We would just press the autoplay button again and jitter the rate again with our 31416th simulation, none the wiser. There really is no way to find the <em>exact</em> true value if the only thing we can do is run the simulation again and again.</p>
	<p>But we'll get close. How close, exactly? Like, from that 7/100 victory rate that I got earlier, can I say something like "I don't know the exact rate, but I'm sure it'll be between 6% and 8%"? Appealing to the intuition we described in the last paragraph, we know that this 6-to-8 interval should decrease in size as we do more and more simulations.</p>
	<p>But&hellip; not quite. Even if the true win rate is 50%, or 90%, or 99%, there is still a technically nonzero probability that we get an experimental result of 7 victories out of 100 total games, so we can't rule those rates out completely. It's highly unlikely, but this chance will never reach zero. If you do the math, it turns out that if the true rate is 50%, then there's a \(1.26 \times 10^{-20}\) chance of getting exactly 7 victories, and of course that chance only goes down further from there as you increase the true win rate&mdash;but the key here is that it's still a number above zero. The details of how to get this number are not necessarily relevant, though I'll include them here if you want to see.</p>
	<details>
		<summary>Calculations (click to reveal)</summary>
		<div>
			<p>This is a standard binomial distribution question. Copying the formula <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Probability_mass_function">directly from Wikipedia</a>, we have
				\[\textrm{Prob}\left(k,n,p\right) = \binom{n}{k} p^k (1-p)^{n-k}\]
			where \(k\) is the number of victories that we're asking about, \(n\) is the total number of simulations we run, and \(p\) is the true victory rate of a single simulation. Also remember that \(\binom{n}{k}\) is how we notate n-choose-k: \(\binom{n}{k}=\frac{n!}{k!(n-k)!}\).
			</p>
			<p>Then it's just a plug-and-chug problem. \(k=7\) and \(n=100\), and we're interested in the case where \(p=0.5\). Plugging everything in we get
				\[\begin{aligned}\textrm{Prob}\left(k=7,n=100,p=0.5\right) &= \binom{100}{7} 0.5^7 (0.5)^{93}\\
				&= 1.26 \times 10^{-20}\end{aligned}\]
			</p>
			<p>If we increase \(p\) to \(0.9\), we get \(7.66 \times 10^{-84}\), and if we increase \(p\) again to \(0.99\), we get \(1.49 \times 10^{-176}\), truly unfathomably tiny. For comparison, if \(p = 0.07\), which is what we would expect the true value to be close to, we get \(0.154\) or just over 15%.</p>
		</div>
	</details>
	<p>So we can't technically exclude this possibility if we want to be <em>truly</em> 100% sure. But it feels almost disingenuous to say that it's possible when it happens <em>so</em> infrequently.</p>
	<p>So maybe we're okay with not being 100% sure, but just being 99% sure is good enough. That is, if we make 100 of these 99%-sure bets in different experiments, we should get about one wrong, on average. If we're okay with that, then we might be able to find an answer like "I'm 99% sure that the true rate is within the range 7.0&plusmn;1.0%." To use statistics terminology, we're trying to find a <em>confidence interval</em>, in this case the 99% confidence interval.</p>
	<p>And at this point I think we've identified what exactly we're looking for in order to experimentally quantify our victory rate. It's time to bring it all together.</p>
</div>

<div class="content">
	<h2>Time for some Real Math&trade;</h2>
	<p>So first, let's recap, because there are a lot of numbers flying around here. And because we're now doing Real Math&trade;, let's give make them variables and give them all letter names. To illustrate with a concrete example that's bigger than a single 100&times; sample size, let me actually run the simulation myself, give me a moment.</p>
	<p>&hellip;</p>
	<p>Okay, great. I got 44 victories out of 500 total simulations, for a win rate of 8.8%</p>
	<ul>
		<li><strong>The experimentally determined win rate:</strong> For me, that was 8.8%. Let's call that \(r\), for rate.</li>
		<li><strong>The true win rate:</strong> We don't know its value, and we won't be able to find its value exactly; that's the whole point. Let's give it the symbol \(r'\), with a prime mark to denote that it's the real deal.</li>
		<li><strong>The number of total simulations we did:</strong> Earlier, we intuited that this would be important, as we would trust an experimental rate more if it came from a larger average. I did 500 simulations in my case. Let's call this number \(n\), for number of simulations.</li>
		<li><strong>The maximum error to expect:</strong> By this I mean the maximum distance from our experimental win rate that we expect the true rate to be, i.e. half the size of the confidence interval. This is something we're trying to calculate, so I can't give you what the number will be just yet for my real example, but in my hypothetical example in the previous section of 7.0&plusmn;1.0%, I'm talking about the 1.0%. Traditionally this is called \(t\), for whatever reason. If you make the d in "distance" voiceless, you get a "t" sound, maybe&hellip;?</li>
		<li><strong>How confident we want to be in our range:</strong> We said 99% sure above, so let's just stick with this value for now. It'll turn out to be more useful for us to name the complement: how <em>unsure</em> we are that our range is correct, 1% in this case. Let's call this "unconfidence" \(P\) for probability of a mistake, where a mistake is when the true rate lies outside our maximum error bounds.</li>
		<li><strong>The range that we're 100% sure the true rate will be in:</strong> Now here's a weird number to keep track of. Above, we were talking about how, if we want to be truly 100% sure we didn't miss anything, we would have to include the possibility of rates all the way up to 100%. You can do the same logic to say you have to include the possibility of rates all the way down to 0%. These absolute bounds, 0% and 100%, will actually turn out to be useful. Let's simply give them the names \(a=0\) and \(b=1\).</li>
	</ul>
	<p>So there we have our seven numbers: \(r, r', n, t, P, a, b\). You perhaps have guessed by now, but I've been leading up to a magic formula that statisticians have come up with for exactly our problem, figuring out how close an experimental result is to the true result, and it uses these seven quantities in it. Well, actually, six of them&mdash;we'll come back to \(P\) in a moment.</p>
	<p>So, drum roll please, here I present to you Hoeffding's Inequality:
		\[\rm{Prob}\left(\left|r - r'\right| &ge; t\right) &le; 2 \exp \left(\frac{-2nt^2}{\left(b-a\right)^2}\right) \]
	</p>
	<p>&hellip;Yep, that sure is an inequality. I'm not going to try to derive it here. I'll leave <a href="http://cs229.stanford.edu/extra-notes/hoeffding.pdf">a link to a PDF that derives it</a>, but be warned that the math goes into much more hardcore statistics than what I'm doing anywhere on this page. Instead, let's talk about what this result means.</p>
	<p>Let's first look at the left hand side. Reading it off, it's the probability that the absolute value of the difference between \(r\) and \(r'\) (our experimental and true rates) is more than our maximum error bounds \(t\). This is basically just \(P\), the probability of making a mistake; we can actually replace the entire left side with \(P\). That gets rid of \(r\) and \(r'\) from our calculation entirely! Which is good; we didn't know \(r'\) to plug in.</p>
	<p>And the right hand side? That's the useful part. It's some expression involving \(t\), \(n\), \(a\), and \(b\). We have numbers for three of them: \(n\), \(a\), and \(b\). In fact, let me plug in \(a\) and \(b\) immediately, to clean that up, because they're just 0 and 1. I'll leave \(n\) alone for the moment because although my own \(n\) is 500, I don't know how many times you did the simulation. We get:
		\[P &le; 2 \exp \left(-2nt^2\right) \]
	</p>
	<p>What we're trying to do is keep P low, lower than 1%. The way we can do that is enforce that the right hand side is no greater than 1%, because the left hand side cannot go above that. We're trying to make sure we're okay even in the "worst" case, which is when \(P\) is so high that it starts to equal the right side. So let's change that inequality sign into an equals sign.</p>
	<p>So we have only one variable left, \(t\). That makes sense; we went into this wondering how wide our interval should be, which is exactly what \(t\) tells us. Now all we have to do is solve for t:
		\[\begin{aligned}
		P &= 2 \exp \left(-2nt^2\right)\\
		t &= \sqrt{ -\frac{1}{2n} \ln\left({\frac{P}{2}}\right) }
		\end{aligned}\]
	</p>
	<p>Let me give you a little calculator for running numbers through that last equation:</p>
	<iframe src="hoeffdinginequalitycalculator.html" title="Hoeffding Inequality t calculator" id="hoeffdinginequalitycalculator" class="calculatoriframe"></iframe>
	<p>You can plug in your numbers for \(P\) and \(n\), but for me, what I get if I plug my numbers is&hellip; 7.3%.</p>
	<p>So, uh, yeah, I'm 99% sure that the rate is 8.8&plusmn;7.3%, or somewhere between 1.5% and 16.1%. I'm&hellip; sure that's true, but geez, what a uselessly large range.</p>
</div>

<div class="content">
	<h2>The Parameters of Our Horseshoes and Hand Grenades</h2>
	<p>Can we fiddle with the parameters to make this more useful? We chose \(n=500\) because that's how many simulations I ran, and we somewhat arbitrarily chose \(P=0.01\) as our acceptable mistake rate. But can we change these two values to get \(t\) to be something in the realm of reasonable?</p>
	<p>Well, we have our equation. We could keep plugging numbers into the calculator above. But it'd be nice to see the whole equation all at once, in a graph. Unfortunately, graphing two input variables and one output variable is a bit difficult. We can attempt to show a 3D plot, but those are always a little bit harder to interpret. I think it would be more useful to see two variables at a time on a 2D plot, holding one input variable constant and putting the other one on the x axis (and of course the output variable \(t\) is on the y axis).</p>
	<figure class="fullwidth">
		<img src="img/t_vs_n.png" alt="t vs. n graph">
		<img src="img/t_vs_P.png" alt="t vs. P graph">
		<br>
	</figure>
	<p>Let's take a moment to familiarize ourselves with these graphs. On the left graph, we start by choosing \(P\) and fixing it to a value; for example the top blue line is a 1% mistake rate. Then, we can choose an \(n\) value along the x-axis: we can imagine doing an experiment and sort of progressing along the x-axis until we get bored and stop. Then, of course, we read up to the blue line to get our final value for \(t\). The right graph is the opposite: each line represents an experiment done with a particular number of simulations (for example, the blue line is 300 simulations), and along the x-axis we consider what happens as we further lower our standards from a 1% mistake rate all the way up to accepting a 20% mistake rate.</p>
	<p>The first thing to notice is that changing the mistake rate \(P\) that we're willing to accept has only a small effect: you can tell that on the left graph because all the lines are clustered very close together, while on the right graph the lines are largely flat, except at the very lowest \(P\) values.</p>
	<p>On the other hand, changing \(n\) has a large effect (at least, changing \(n\) by orders of magnitude; notice that the x-axis is on a log scale). We can tell this from the curves on the left graph sweeping down significantly, or from the right graph by the fact that the curves are spaced wide apart. On the right graph, if we start from the \(n=300\) blue line and \(P=1\%\) at the left of the graph, we could try to accept more and more error, all the way up to \(P=20\%\), but even allowing for that huge acceptable mistake rate is not as effective as just doing more experiments instead, jumping down from the \(n=300\) blue line to the \(n=1000\) orange line.</p>
	<p>So if we want to shrink our error bounds \(t\), it's better to increase the number of simulations \(n\) than our maximum mistake rate \(P\), as long as we can do so by orders of magnitude.</p>
</div>

<div class="content">
	<h2>But wait! There's more! More parameters, that is</h2>
	<p>In the last section, we treated \(n\) and \(P\) as our input variables, but we have three variables that are all interrelated with each other. We can just as well fix \(t\) and \(P\), and from those two calculate \(n\), how many simulations we are required to do to achieve that error bound and mistake rate. Or we could fix \(n\) and \(t\) and calculate \(P\), seeing what the mistake rate is going to be if we insist on a certain number of experiments and error bound.</p>
	<p>So let's graph these cases too. To be clear, all these graphs are graphing the same single equation, but we're just looking at different ways of slicing 2D graphs from the full 3D graph.</p>
	<figure class="fullwidth">
		<img src="img/n_vs_t.png" alt="n vs. t graph">
		<img src="img/n_vs_P.png" alt="n vs. P graph">
		<br>
	</figure>
	<p>I won't spend as much time on this pair of graphs as I did the first pair, as they look pretty similar. Adjusting \(P\) has a small effect on the output, while adjusting the other parameter (whether that's \(t\) or \(n\)) has a much bigger effect.</p>
	<p>Maybe it shouldn't be a surprise that \(t\) and \(n\) act so similarly. In the equation itself (\(P = 2 \exp \left(-2nt^2\right)\), if you'll recall), \(t\) and \(n\) are in almost the same position, inside the exponent. The only difference is that \(t\) is squared while \(n\) is not.</p>
	<figure class="fullwidth">
		<img src="img/P_vs_n.png" alt="P vs. n graph">
		<img src="img/P_vs_t.png" alt="P vs. t graph">
		<br>
	</figure>
	<p>On the other hand, putting the mistake rate \(P\) on the y-axis looks pretty different. The two graphs look pretty similar to <em>each other</em>, though, again emphasizing that \(t\) and \(n\) act pretty similarly.</p>
	<p>But there's another thing to notice about this graph: look at the values on the y-axis. It ranges from 0 to 2. A probability of 2? Wait, what does that mean? Did we do something wrong?</p>
	<p>No, in fact, we didn't. Remember that Hoeffding's Inequality is, well, an inequality. We've been treating it like an equality because equality is the worst case scenario, but all the original statement is saying is that the real probability is something <em>less</em> than the \(P\) that we're calculating here. And, well, yes, the probability <em>is</em> less than 200%, because all probabilities are less than 200%. It's a <em>true</em> statement, technically, even if not a <em>useful</em> one.</p>
	<p>So this is a reminder that in our original 8.8&plusmn;7.3% calculation, we're probably <em>more</em> than 99% sure that the true rate is within this range; it's just that we can't say how much more. In practice, Hoeffding's Inequality gives a reasonably tight bound as long as \(n\) is sufficiently large, taking us past the part of the curve on the left graph where P is near or above 100%.</p>
	<p>Is <em>this</em> such a case, where \(n\) is high enough that we're in the "useful" regime?</p>
	<p>Um&hellip; I was kind of hoping so, which is why I went through all that math with you. But just looking at our results far, I think that's not actually the case here&mdash;running this again and again, we get repeatable results that suggest a much tighter bound. I suppose that's why you'll hear about Hoeffding's Inequality mostly in the context of something like machine learning, where it's common to have many tens of thousands of test cases if not a couple of orders of magnitude more, as opposed to the hundreds or couple thousands that we have now.</p>
	<p>So&hellip; let's try something else. There are other ways of calculating a confidence interval other than Hoeffding's Inequality, but at this point I'm a little tired of this experimentation; I think you'll agree. Let's just try to figure this out analytically.</p>
	<p>But before we do, I'll leave you with one more simulation you can play around with, which calculates the Hoeffding Inequality confidence intervals for you:</p>
	<iframe src="victorypercentagegame_withcalculations.html" title="Clock Solitaire" id="victorypercentagegame_withcalculations" class="gameiframe"></iframe>
</div>

<div class="content">
	<h2>The Harbinger of Doom (But Sometimes Victory)</h2>
	<p>Wait, what were we even trying to do again? That last simulation doesn't even have cards in it; we got real abstract there. Let me remind us what we're doing: we're trying to find the win rate of Clock Solitaire.</p>
	<p>So. Where do we begin with our analysis? Hmm&hellip; Well, remember that observation that we made at the very top of this page, with the very first autoplaying game? It was that when the game ends, whether victoriously or in failure, it was always a King that sat on top of our waste pile. Is this relevant to our victory condition? Maybe. Let's investigate this further. Can we prove why this is the case?</p>
	<figure class="floatright">
		<img src="img/Seven_with_empty_pile.png" alt="a game with an empty 7 o'clock pile and a 7 on the top of the face-up waste pile" width="300px">
		<figcaption>How might we get into this situation? (Spoilers: we can't.)</figcaption>
	</figure>
	<p>Actually, what might be helpful is to frame this question another way: why is it that we never end at any other card?</p>
	<p>Well, how would we end on, say, the 7 o'clock pile? Let's consider just the loss condition for now, when we get pointed to a pile on the clock face that's already empty. In this case, that would look something like the situation pictured on the right: when there's a Seven on the top of the waste pile, but the 7 o'clock pile is already empty&mdash;that is, we've previously already removed all four cards from the 7 o'clock pile.</p>
	<p>So then we ask: how did we remove all four of those cards? And the answer, of course, is that we remove a card from the 7 o'clock pile every time we moved a Seven into the waste pile. So if we removed four cards from the 7 o'clock pile, that means we previously drew four Sevens.</p>
	<p>But wait, if we previously already drew all four Sevens, how do we have another Seven in the waste pile now? And here lies the impossibility: we can't be in this situation at all, because for the pile to be empty, we would have to have drawn all four Sevens, but that would mean there are no more Sevens left to point at the empty pile.</p>
	<p>There's nothing special about Seven, of course; this logic is true for all twelve of the clock face number piles. We will never get stuck on an Ace, or a Five, or a Ten. But the Kings and the 13 o'clock pile is different. Do you see why?</p>
	<p>Well, we start the game with a move from the 13 o'clock pile, even though we haven't seen a King yet&mdash;we get one move from that pile for free. This means that once the pile is empty, we'll only have seen three Kings. The fourth King, once it's removed from the clock face, will point us back to the empty pile, and we get stuck. So a King can get us stuck, while no other card can.</p>
	<p>Mini exercise to check your understanding: if we wanted to play this with a 54-card deck, adding in the two Jokers as a 14 o'clock, how would we modify the setup?</p>
	<details>
		<summary>Answer (click to reveal)</summary>
		<p>Add an additional 14 o'clock pile in your setup (maybe next to the 13 o'clock pile in the center of the clockface), with only two cards in it. The first move could be from the 13 o'clock pile or the 14 o'clock pile; it doesn't really matter. But everything else works identically.</p>
	</details>
	<p>All right, for why the Kings show up during losses, I think that's settled. But what about when we win? Why is the final card that we clear from the clock face always a King?</p>
	<p>Well, what does it mean to win? The game rules state that we win when we remove the last card from the clock face. But actually it might be easier to think about it a different way: we win if we never lose. If we never lose, but we keep playing a card every turn, then after 52 turns of not losing, we'll have won.</p>
	<p>We already said that our only loss condition is seeing the fourth and final King. So if we haven't lost by turn 52, then we did not yet see the fourth King before this final card. But of course the fourth King still has to be in the deck somewhere; it must be this last card.</p>
	<p>So that's why the fourth King is a harbinger of victory sometimes too, not just defeat.</p>
</div>

<div class="content">
	<h2>Bringing It All Back Together</h2>
	<p>That's an interesting result. But it doesn't exactly get us to the victory rate. &hellip;Or does it?</p>
	<p>We now know about the last card. It has to be a King. We just said that as long as the 52nd card we draw is a King, we've won. And of course, the probability that any random card in a shuffled deck is a King is simply 1 in 13, or about 7.69%.</p>
	<p>Is it really so simple? All the stuff in between, all that moving cards around, none of it matters, as long as the final card is a King? But yes, that's really it. That's the number we're looking for, our probability of winning a game of Clock Solitaire. 7.69%.</p>
	<p>Well, that was anticlimactic. After all that work with experimentation and the actual number falls out so easily by just thinking about it. I'd love to say this is all part of my plan, that I was trying to get you to feel the Real Math&trade; experience of trying to do something entirely the wrong way and then ultimately finding out the answer was actually really easy to get if you did it a different way. But, uh, actually, although that's what this ended up being, I had originally hoped the whole error analysis thing would actually be more useful to this experiment than it ended up being.</p>
	<p>Hopefully it was interesting, at least, though. Hoeffdinger's Inequality <em>is</em> a useful inequality to give us error bounds, in other circumstances. Just not today's circumstance. Regardless, thanks for sticking around!</p>
	<details>
		<summary>A footnote (click to reveal)</summary>
		<p>By the way, there is one part of my argument here that still feels a bit handwavy. Are we sure that the last card we see is actually a randomly shuffled card? After all, we're doing all this back-and-forth clock man≈ìuvering; maybe this changes the probability of the last card we're going to see. That's how the Monty Hall Problem works.</p>
		<p>In this case, that's not a problem&mdash;and our experiments from earlier do support our analytical conclusions. If we draw the Queen of Spades, we don't learn anything about the placement of the remaining cards except that none of them are the Queen of Spades. There wasn't any correlation between the shuffled cards and their positions when we put them down because they were random to begin with, and we're not going to spontaneously get order out of randomness by choosing effectively random cards. (If this still feels a little bit handwavy, I'll leave any further formalization of this As An Exercise For The Reader&mdash;because this is Real Math&trade;, I get to say that!)</p>
	</details>
</div>

<div class="content">
	<h2>To Go Even Further Beyond</h2>
	<p>There are of course many more questions we can ask about this game.</p>
	<p>I don't have time to go into all of them, of course, but I'll leave you with some of the questions, at least, for you to explore about on your own time:</p>
	<ul>
		<li><strong>The average number of remaining cards:</strong> Rather than asking the simple "how often do we win?" yes-or-no question, we can also consider the number of cards remaining on the clock face if we lose. Then, instead of a single probability, we would then be dealing with a probability <em>distribution</em>, i.e. a whole string of probabilities: the probability of 0 cards remaining (i.e. winning), the probability of having 1 card remaining, the probability of having 2 cards remaining, all the way up to the probability of 52 cards remaining. What does this distribution look like? If you do repeated experiments to find this out, as we did today, what does Hoeffding's inequality look like? (Hint: \(a\) and \(b\) aren't 0 and 1 anymore!)</li>
		<li><strong>Reintroducing choice:</strong> As we've already established, this is a game that is purely deterministic, but we can actually make it so that the player has some agency and strategy. Now, each of the thirteen piles is made of four faceup cards, rather than facedown ones, and making a move from a pile means choosing <em>any</em> card from the pile, not necessarily the top one. What would be a good strategy? Are all games winnable? What if we change the goal to trying to remove the <em>least</em> number of cards from the clock face, instead of the most? What kinds of strategies would work best there? (Incidentally, I often like playing other solitaire card games face-up instead of face-down, because then I can look and plan ahead, so I can actually strategize more effectively.)</li>
		<li><strong>The 100 Prisoners Puzzle:</strong> If you've heard of the 100 Prisoners Puzzle, you may have found some similarities between this and the solution to that puzzle. If you you follow math edutainment YouTube (and if you're finding this from SoME2, you probably are), you may have seen some similarities between this game and the solution to the 100 Prisoners Puzzle, most recently covered by <a href="https://www.youtube.com/watch?v=iSNsgj1OCLA">Veritasium</a> but also previously covered by <a href="https://www.youtube.com/watch?v=a1DUUnhk3uE">Stand-up Maths</a> and <a href="https://www.youtube.com/watch?v=eivGlBKlK6M">MinutePhysics</a> (and probably others). Is there any deeper connection here?</li>
		<li><strong>And more!</strong> There are probably plenty of other questions that might have come to mind for you that I haven't even thought of. Maybe it's not even about Clock Solitaire, but was still inspired by what we talked about here. Go ahead and explore those ideas! Doing stuff on your own is the <em>real</em> Real Math&trade;.</li>
	</ul>
</div>

<hr>
<h1>Acknowledgments</h1>
<div class="content">
	<p>This page was created by Viola Buddy for the Summer of Math Exposition 2 (SoME2), an event organized by the YouTube channel 3Blue1Brown to encourage people to create explanations of math or math-related subjects in any online medium. This page was written in HTML/Javascript, with equations written using the <a href="https://www.mathjax.org/">MathJax</a> library. Graphs were made using Python's <a href="https://matplotlib.org/">Matplotlib</a> graphing library. Public domain playing card vector images by Byron Knoll (card backs are by Viola Buddy).</p>
	<p>Clock solitaire itself is a traditional card game with no clear inventor; <a href="https://en.wikipedia.org/wiki/Clock_(card_game)">here</a> is its Wikipedia page. Note that traditionally, instead of moving cards to a waste pile, you place them under their respective pile, face up, but they are never moved again. I thought that would be a bit messy to show here, and a bit of a distraction, so I opted to throw them into a waste pile instead (and that's what I do when playing this game in real life with physical cards, since you don't need to shuffle quite as thoroughly afterwards because they don't end up sorted).</p>
</div>

</body>
</html>